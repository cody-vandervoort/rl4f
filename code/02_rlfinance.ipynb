{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Finance\n",
    "\n",
    "**Chapter 02 &mdash; Deep Q-Learning**\n",
    "\n",
    "&copy; Dr. Yves J. Hilpisch\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be6f8b-e00e-402c-9df1-1d3f16e76c7e",
   "metadata": {},
   "source": [
    "## CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3924c3-2cad-4400-8806-5acf2f4b9b16",
   "metadata": {},
   "source": [
    "### The Game Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f3a51a-71e6-497d-bab3-926444a6bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19725f2-a026-487e-826c-00fa5fce71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af76fb4e-3b31-4465-bff5-e5f8362af3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb45da1-6f9c-464d-bb16-e098ddd52838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e8ec50-f5a4-4706-8937-6724582ebdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[env.action_space.sample() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592d3ddc-3958-42ff-b4c7-8924ce0a343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19474f1a-29c3-4cc2-89f6-6226845f5468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdd054d-4a5e-429e-9e44-3e436a20446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03349816,  0.0096554 , -0.02111368, -0.04570484], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(seed=100)\n",
    "# cart position, cart velocity, pole angle, pole angular velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875c67b7-4817-4fac-8fbb-0596c399af96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03369127, -0.18515752, -0.02202777,  0.24024247], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be7afb1-e69d-41d7-b869-c73747e38b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02998812,  0.01027205, -0.01722292, -0.05930644], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f6e49b-3308-418a-999c-f7d6a052cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "    def play(self, episodes=1):\n",
    "        self.trewards = list()\n",
    "        for e in range(episodes):\n",
    "            self.env.reset()\n",
    "            for step in range(1, 100):\n",
    "                a = self.env.action_space.sample()\n",
    "                state, reward, done, trunc, info = self.env.step(a)\n",
    "                if done:\n",
    "                    self.trewards.append(step)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffbb689-b81e-48cc-9fac-3a7dec9c1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RandomAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb3b03c-ded1-4ca7-80d2-e316635379b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.play(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b83a7c9-485a-433d-b637-9ffbe6fe7146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 17, 10, 13, 13, 12, 35, 21, 17, 26, 16, 49, 20, 19, 26]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra.trewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27d9d910-4f2d-4d7b-bcaa-a28747474c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(ra.trewards) / len(ra.trewards), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e1594d-ea7c-49e9-9149-92848ba72440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa105bbb-727f-488d-8152-b5c1cc4d7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a21cd6c5-058b-45cb-abfa-78a9cbb3633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0264fac6-2c4a-4ea3-9031-e5006dce93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.legacy.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c28ee7-4be2-459c-8e27-029ec6ff4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "tf.random.set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "072e8f75-0936-434f-ad65-c2f7cff91b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent:\n",
    "    def __init__(self):\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.9975\n",
    "        self.epsilon_min = 0.1\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.9\n",
    "        self.trewards = list()\n",
    "        self.max_treward = 0\n",
    "        self._create_model()\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "    def _create_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, activation='relu', input_dim=4))\n",
    "        self.model.add(Dense(24, activation='relu'))\n",
    "        self.model.add(Dense(2, activation='linear'))\n",
    "        self.model.compile(loss='mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03e2299c-14bd-4cc8-af41-89b69d532544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent(DQLAgent):\n",
    "    def act(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "    def replay(self):\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        for state, action, next_state, reward, done in batch:\n",
    "            if not done:\n",
    "                reward += self.gamma * np.amax(\n",
    "                    self.model.predict(next_state)[0])\n",
    "            target = self.model.predict(state)\n",
    "            target[0, action] = reward\n",
    "            self.model.fit(state, target, epochs=2, verbose=False)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bf59f89-41a4-4f6e-8635-0513b3c3d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent(DQLAgent):\n",
    "    def learn(self, episodes):\n",
    "        for e in range(1, episodes + 1):\n",
    "            state, _ = self.env.reset()\n",
    "            state = np.reshape(state, [1, 4])\n",
    "            for f in range(1, 5000):\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, trunc, _ = \\\n",
    "                    self.env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, 4])\n",
    "                self.memory.append(\n",
    "                    [state, action, next_state, reward, done])\n",
    "                state = next_state\n",
    "                if done or trunc:\n",
    "                    self.trewards.append(f)\n",
    "                    self.max_treward = max(self.max_treward, f)\n",
    "                    templ = f'episode={e:4d} | treward={f:4d}'\n",
    "                    templ += f' | max={self.max_treward:4d}'\n",
    "                    print(templ, end='\\r')\n",
    "                    break\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                self.replay()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a44a5f9-af9b-4929-a5c4-19e87f871c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent(DQLAgent):\n",
    "    def test(self, episodes):\n",
    "        for e in range(1, episodes + 1):\n",
    "            state, _ = self.env.reset()\n",
    "            state = np.reshape(state, [1, 4])\n",
    "            for f in range(1, 5001):\n",
    "                action = np.argmax(self.model.predict(state)[0])\n",
    "                state, reward, done, trunc, _ = self.env.step(action)\n",
    "                state = np.reshape(state, [1, 4])\n",
    "                if done or trunc:\n",
    "                    print(f, end=' ')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64417ca0-49ba-4558-8c92-d89604ff3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQLAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77a72ab-5a4b-4d3d-863a-f8d08d2e3ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode=1500 | treward= 254 | max= 500\n",
      "CPU times: user 2min 11s, sys: 23.2 s, total: 2min 34s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%time agent.learn(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbfc1255-66fe-4c69-9135-70100b981109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09997053357470892"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af72f8d3-4e2a-4d0f-8311-a56ba4487832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 211 206 101 198 234 115 287 241 116 98 201 120 174 95 "
     ]
    }
   ],
   "source": [
    "agent.test(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
    "\n",
    "<a href=\"https://tpq.io\" target=\"_blank\">https://tpq.io</a> | <a href=\"https://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
